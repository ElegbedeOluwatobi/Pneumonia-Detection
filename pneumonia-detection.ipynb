{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1426603,"sourceType":"datasetVersion","datasetId":835414}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-02T14:49:27.157389Z","iopub.execute_input":"2023-12-02T14:49:27.157695Z","iopub.status.idle":"2023-12-02T14:49:39.223956Z","shell.execute_reply.started":"2023-12-02T14:49:27.157668Z","shell.execute_reply":"2023-12-02T14:49:39.222945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-12-02T14:49:39.225616Z","iopub.execute_input":"2023-12-02T14:49:39.226083Z","iopub.status.idle":"2023-12-02T14:49:51.927309Z","shell.execute_reply.started":"2023-12-02T14:49:39.226051Z","shell.execute_reply":"2023-12-02T14:49:51.926509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\n\n# Set your paths\ntrain_data_dir = '/kaggle/input/labeled-chest-xray-images/chest_xray/train'\n\n# Get a list of class names (assuming subdirectories are named after classes)\nclass_names = sorted(os.listdir(train_data_dir))\n\n# Display the first few images from each class\nnum_images_to_display = 3\n\nfor class_name in class_names:\n    class_path = os.path.join(train_data_dir, class_name)\n    class_images = os.listdir(class_path)[:num_images_to_display]\n\n    print(f\"\\nClass: {class_name}\")\n    plt.figure(figsize=(15, 3))\n\n    for i, image_name in enumerate(class_images, 1):\n        img_path = os.path.join(class_path, image_name)\n        img = image.load_img(img_path, target_size=(224, 224))\n        plt.subplot(1, num_images_to_display, i)\n        plt.imshow(img)\n        plt.title(f\"Image {i}\")\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T14:49:51.928465Z","iopub.execute_input":"2023-12-02T14:49:51.929005Z","iopub.status.idle":"2023-12-02T14:49:53.493708Z","shell.execute_reply.started":"2023-12-02T14:49:51.928979Z","shell.execute_reply":"2023-12-02T14:49:53.492634Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/labeled-chest-xray-images/chest_xray/train'\ntest_data_dir = '/kaggle/input/labeled-chest-xray-images/chest_xray/test'\n\n# Get a list of class names (assuming subdirectories are named after classes)\nclass_names_train = sorted(os.listdir(train_data_dir))\nclass_names_test = sorted(os.listdir(test_data_dir))\n\n# Display the number of images in each class for the training set\nprint(\"Training Dataset:\")\nfor class_name in class_names_train:\n    class_path = os.path.join(train_data_dir, class_name)\n    num_images = len(os.listdir(class_path))\n    print(f\"Class: {class_name}, Number of Images: {num_images}\")\n\n# Display the number of images in each class for the test set\nprint(\"\\nTest Dataset:\")\nfor class_name in class_names_test:\n    class_path = os.path.join(test_data_dir, class_name)\n    num_images = len(os.listdir(class_path))\n    print(f\"Class: {class_name}, Number of Images: {num_images}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-02T14:49:53.496475Z","iopub.execute_input":"2023-12-02T14:49:53.497112Z","iopub.status.idle":"2023-12-02T14:49:53.514121Z","shell.execute_reply.started":"2023-12-02T14:49:53.497076Z","shell.execute_reply":"2023-12-02T14:49:53.513234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA AUGMENTATION**","metadata":{}},{"cell_type":"code","source":"# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255.,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale=1.0/255.)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_data_dir,\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    shuffle=True,\n                                                    target_size=(224, 224))  # Corrected target_size\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(test_data_dir,\n                                                        batch_size=20,\n                                                        class_mode='binary',\n                                                        shuffle=False,\n                                                        target_size=(224, 224))  # Corrected target_size","metadata":{"execution":{"iopub.status.busy":"2023-12-02T14:49:53.515076Z","iopub.execute_input":"2023-12-02T14:49:53.515322Z","iopub.status.idle":"2023-12-02T14:49:55.347724Z","shell.execute_reply.started":"2023-12-02T14:49:53.515302Z","shell.execute_reply":"2023-12-02T14:49:55.346960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers, models\n# Set your image dimensions\nimg_width, img_height = 224, 224\n\n# Load the pre-trained VGG16 model\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n\n# Freeze the layers of the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Create your model\nmodel = models.Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))  # Change this to the number of classes you have\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',  # Change this to 'categorical_crossentropy' if you have multiple classes\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T14:49:55.348929Z","iopub.execute_input":"2023-12-02T14:49:55.349609Z","iopub.status.idle":"2023-12-02T14:50:02.226801Z","shell.execute_reply.started":"2023-12-02T14:49:55.349557Z","shell.execute_reply":"2023-12-02T14:50:02.225763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T14:50:02.228180Z","iopub.execute_input":"2023-12-02T14:50:02.228577Z","iopub.status.idle":"2023-12-02T14:50:02.252736Z","shell.execute_reply.started":"2023-12-02T14:50:02.228542Z","shell.execute_reply":"2023-12-02T14:50:02.251804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Define EarlyStopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Define ModelCheckpoint callback to save the best model during training\nmodel_checkpoint = ModelCheckpoint('chest_model.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Fit the model with callbacks\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=30,\n    validation_data=validation_generator,\n    validation_steps=len(validation_generator),\n    callbacks=[early_stopping, model_checkpoint]  # Add callbacks here\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:21:33.265076Z","iopub.execute_input":"2023-12-02T15:21:33.265474Z","iopub.status.idle":"2023-12-02T16:02:05.200884Z","shell.execute_reply.started":"2023-12-02T15:21:33.265444Z","shell.execute_reply":"2023-12-02T16:02:05.199816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nimport seaborn as sns\nmodel = tf.keras.models.load_model('chest_model.h5')  # Load the best model\nval_predictions = model.predict(validation_generator)\nval_pred_classes = (val_predictions > 0.5).astype(int)  # Binary classification threshold\n\n# Get true classes\nval_true_classes = validation_generator.classes\n\n# Plot the confusion matrix with numbers\ncm = confusion_matrix(val_true_classes, val_pred_classes)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nclasses = validation_generator.class_indices.keys()\ntick_marks = range(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\nplt.show()\n\n# Print the classification report\nprint(\"Classification Report:\\n\", classification_report(val_true_classes, val_pred_classes, target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:09:04.541458Z","iopub.execute_input":"2023-12-02T16:09:04.542345Z","iopub.status.idle":"2023-12-02T16:09:11.170310Z","shell.execute_reply.started":"2023-12-02T16:09:04.542293Z","shell.execute_reply":"2023-12-02T16:09:11.169259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Assuming your model file is 'best_model.h5'\nmodel_file_path = 'chest_model.h5'\n\n# Create a link to download the file\nFileLink(r'chest_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-02T16:33:48.718437Z","iopub.execute_input":"2023-12-02T16:33:48.719309Z","iopub.status.idle":"2023-12-02T16:33:48.725599Z","shell.execute_reply.started":"2023-12-02T16:33:48.719268Z","shell.execute_reply":"2023-12-02T16:33:48.724633Z"},"trusted":true},"execution_count":null,"outputs":[]}]}